% Extensions
%extAction('.').
%extUnion('.').

%_lex('-BRIDGE-', ['fracQuant/3', 'countQuant/3'])         :- extAction(1). % Generalized quantification: 30% of the cities | 3 cities
%_lex('-BRIDGE-', ['fracTopRanked/2', 'countTopRanked/2']) :- extAction(1). % Generalized quantification: 30% of the largest cities | 3 largest cities
%_lex(['fraction', 'percent'], 'fracQuant/3').


%%%BEGIN WACKYPEDIA 10 per PREDICATES
%%%predicates.dlog predicate context distribution from Wackypedia as Lexical triggers
%_lex(['em', 'computed', 'classic', 'argmax', 'iteration', 'viterbi', 'maximization', 'state', 'each', 'path'], ['argmax/4']).
%_lex(['major', 'army', 'frank', 'later', 'rank', 'one', 'promoted', 'new', 'general', 'first'], ['rank/2']).
%_lex(['used', 'though', 'many', 'one', 'although', 'time', 'not', 'such', 'more', 'until', 'first'], ['not/3']).
%_lex(['square', 'density', 'average', 'people', 'per', 'one', 'mile', 'km', 'smile', 'population'], ['mile/2']).
%_lex(['school', 'later', 'same', 'one', 'each', 'year', 'following', 'during', 'new', 'first'], ['year/2']).
%_lex(['used', 'stanegate', 'power', 'one', 'effects', 'each', 'negate', 'more', 'road', 'stonegate'], ['negate/2']).
%_lex(['benjamin', 'brahmin', 'amin', 'min', 'vitamin', 'one', 'born', 'franklin', 'new', 'first'], ['min/2']).
%_lex(['rugby', 'union', 'national', 'team', 'trade', 'born', 'communion', 'reunion', 'new', 'workers'], ['union/3']).
%_lex(['gypsum', 'number', 'money', 'sum', 'two', 'one', 'large', 'possum', 'each', 'species'], ['sum/2']).
%_lex(['total', 'square', 'area', 'over', 'percent', 'one', 'miles', 'vote', 'population', 'more'], ['percent/2']).
%_lex(['wireless', 'compare', 'used', 'unless', 'help', 'regardless', 'less', 'nevertheless', 'nonetheless', 'different', 'two', '1', 'much', 'between', 'such', 'one', 'more'], ['compareLess/3']).
%_lex(['population', 'square', 'density', 'km', 'average', 'people', 'squared', 'up', 'against', 'two', 'second', 'mile', 'per', 'error', 'smile', 'one', 'mean'], ['squared_mile/2']).
%_lex(['square', 'density', 'average', 'area', 'people', 'per', 'kilometer', 'kilometers', 'estimated', 'population'], ['kilometer/2']).
%_lex(['compare', 'used', 'help', 'african', 'makeup', 'different', 'two', '1', 'american', 'races', 'native', 'between', 'such', 'white', 'one', 'racial', 'more'], ['compareMore/3']).
%_lex(['population', 'square', 'density', 'people', 'average', 'area', 'squared', 'up', 'against', 'two', 'second', 'kilometer', 'estimated', 'per', 'error', 'one', 'kilometers', 'mean'], ['squared_kilometer/2']).
%_lex(['en', 'ten', 'well', 'number', 'one', 'services', 'best', 'top', 'two', 'tail', 'latin', 'frac', 'atop', 'time', 'stop', 'ranked', 'dlig', 'world', 'league', 'school', 'language', 'list', 'magazine', 'three', 'each', 'tubing', 'calfrac', 'first'], ['fracTopRanked/2']).
%_lex(['animax', 'max', 'climax', 'one', 'lomax', 'miramax', 'series', 'during', 'film', 'first'], ['max/2']).
%_lex(['females', '18', 'over', 'males', 'one', 'every', 'year', '100', 'years', 'age', 'day'], ['every/3']).
%_lex(['perimeter', 'diameter', 'square', 'cm', 'up', 'meter', 'one', 'kilometer', 'long', 'parameter'], ['meter/2']).
%_lex(['equant', 'en', 'frac', 'language', 'point', 'piquant', 'de', 'well', 'one', 'dlig', 'tail', 'latin', 'quant', 'services', 'tubing', 'problem', 'calfrac', 'isoquant', 'model', 'more'], ['fracQuant/3']).
%_lex(['count', 'account', 'son', 'one', 'discount', 'take', 'each', 'more', 'viscount', 'first'], ['count/2']).
%_lex(['given', 'set', 'argmin', 'g', 'f', 'defined', 'median', 'argument', 'unary', 'computable'], ['argmin/4']).
%_lex(['faith', 'court', 'people', 'god', 'support', 'affirm', 'one', 'new', 'love', 'reaffirm'], ['affirm/2']).
%_lex(['square', 'barefoot', 'm', 'two', 'long', 'one', 'located', 'foot', 'left', 'first'], ['foot/2']).
%_lex(['term', 'used', 'word', 'name', 'one', 'crimean', 'above', 'time', 'war', 'mean'], ['mean/2']).
%%%END WACKYPEDIA 10 per PREDICATES

%BEGIN WORDNET PREDICATES
%predicates.dlog synonyms from WordNet as Lexical triggers
_lex(['argmax'], ['argmax/4']).
_lex(['and', 'grade', 'flagrant', 'rank', 'rate', 'file', 'absolute', 'gross', 'sheer', 'station', 'right-down', 'crying', 'glaring', 'out-and-out', 'status', 'membership', 'downright', 'egregious', 'outrank', 'range', 'place', 'social', 'order'], ['rank/2']).
_lex(['not', 'non'], ['not/3']).
_lex(['swedish', 'statute', 'stat', 'land', 'sea', 'geographical', 'naut', 'mi', 'air', 'roman', 'mile', 'knot', 'nautical', 'international', 'admiralty', 'mil'], ['mile/2']).
_lex(['yr', 'twelvemonth', 'class', 'year'], ['year/2']).
_lex(['contravene', 'neutralize', 'contradict', 'nullify', 'belie', 'negate', 'neutralise'], ['negate/2']).
_lex(['dialect', 'min', 'fukkianese', 'taiwanese', 'amoy', 'hokkianese', 'fukien', 'minute'], ['min/2']).
_lex(['matrimony', 'trade', 'conglutination', 'sexual', 'spousal', 'wedlock', 'union', 'sum', 'pairing', 'conjugation', 'labor', 'uniting', 'north', 'relationship', 'unification', 'jointure', 'brotherhood', 'join', 'coupling', 'trades', 'federal', 'marriage', 'mating'], ['union/3']).
_lex(['and', 'kernel', 'heart', 'nitty-gritty', 'essence', 'up', 'summation', 'total', 'nub', 'summarize', 'tote', 'union', 'sum', 'tot', 'add', 'totality', 'money', 'core', 'gist', 'centre', 'tally', 'aggregate', 'marrow', 'meat', 'substance', 'join', 'center', 'of', 'soul', 'together', 'pith', 'amount', 'summate', 'inwardness', 'summarise'], ['sum/2']).
_lex(['percentage', 'pct', 'percent', 'centum', 'per'], ['percent/2']).
_lex(['compare', 'less', 'liken', 'extent', 'a', 'comparison', 'lupus', 'le', 'equivalence', 'comparability', 'lesser', 'to', 'equate', 'erythematosus'], ['compareLess/3']).
_lex(['swedish', 'statute', 'stat', 'square', 'sea', 'geographical', 'mi', 'squared', 'up', 'air', 'naut', 'roman', 'mile', 'mil', 'knot', 'nautical', 'international', 'feather', 'admiralty', 'land'], ['squared_mile/2']).
_lex(['kilometre', 'kilometer', 'klick', 'km'], ['kilometer/2']).
_lex(['compare', 'greater', 'sir', 'liken', 'thomas', 'extent', 'than', 'a', 'comparison', 'equivalence', 'comparability', 'to', 'equate', 'more'], ['compareMore/3']).
_lex(['kilometre', 'square', 'squared', 'up', 'km', 'kilometer', 'klick', 'feather'], ['squared_kilometer/2']).
_lex(['upper', 'exceed', 'graded', 'inning', 'grade', 'circus', 'crown', 'rank', 'height', 'past', 'spinning', 'pass', 'go', 'frac', 'whirligig', 'out', 'lead', 'top', 'tip', 'overstep', 'outrank', 'teetotum', 'order', 'crest', 'meridian', 'tent', 'elevation', 'big', 'tiptop', 'ranked', 'peak', 'stratified', 'superlative', 'pinnacle', 'transcend', 'off', 'acme', 'of', 'clear', 'cover', 'rate', 'side', 'range', 'summit', 'upside', 'place', 'pinch', 'the', 'round'], ['fracTopRanked/2']).
_lex(['boy', 'harm', 'georgia', 'grievous', 'liquid', 'scoop', 'max', 'bodily', 'ecstasy', 'lay', 'easy', 'goop', 'home', 'soap'], ['max/2']).
_lex(['every'], ['every/3']).
_lex(['beat', 'metre', 'time', 'm', 'meter', 'measure', 'cadence'], ['meter/2']).
_lex(['frac', 'quant'], ['fracQuant/3']).
_lex(['count', 'counting', 'depend', 'consider', 'look', 'reckon', 'tally', 'number', 'enumeration', 'matter', 'bet', 'enumerate', 'weigh', 'reckoning', 'calculate', 'numeration', 'numerate'], ['count/2']).
_lex(['argmin'], ['argmin/4']).
_lex(['avow', 'swan', 'confirm', 'substantiate', 'support', 'affirm', 'assert', 'corroborate', 'swear', 'sustain', 'verify', 'aver'], ['affirm/2']).
_lex(['pick', 'foundation', 'infantry', 'ft', 'human', 'metrical', 'groundwork', 'up', 'understructure', 'it', 'pes', 'base', 'animal', 'fundament', 'foot', 'invertebrate', 'hoof', 'leg', 'unit', 'substructure'], ['foot/2']).
_lex(['signify', 'entail', 'mind', 'imply', 'meanspirited', 'have', 'in', 'mingy', 'for', 'tight', 'beggarly', 'intend', 'miserly', 'base', 'hateful', 'of', 'average', 'value', 'stand', 'bastardly', 'think', 'mean'], ['mean/2']).

%END WORDNET PREDICATES
%
%
%%BEGIN WACKYPEDIA PREDICATES
%
%%predicates.dlog predicate context distribution from Wackypedia as Lexical triggers
%_lex(['em', 'computed', 'classic', 'argmax', 'viterbi', 'maximization', 'replace', 'leads', 'itself', 'modeling', 'find', 'calculate', 'next', 'current', 'state', '2', 'optimal', 'channel', 'corresponding', 'possible', 'extending', 'br', 'path', 'iteration', 'each'], ['argmax/4']).
%_lex(['major', 'rank', 'one', 'born', 'captain', 'prank', 'army', 'colonel', 'two', 'sinatra', 'drank', 'new', 'war', 'frank', 'lieutenant', 'military', 'during', 'general', 'later', 'american', 'officer', 'time', 'promoted', 'served', 'first'], ['rank/2']).
%_lex(['people', 'being', 'one', 'not', 'such', 'out', 'even', 'use', 'two', 'much', 'new', 'until', 'more', 'used', 'though', 'very', 'part', 'although', 'known', 'during', 'name', 'many', 'well', 'up', 'time', 'first'], ['not/3']).
%_lex(['square', 'people', 'one', 'mile', 'per', 'density', 'west', 'housing', 'squaremile', 'long', '1', 'located', 'units', 'smile', 'east', 'north', 'half', 'population', 'emile', 'route', 'km', 'road', 'river', 'average', 'south'], ['mile/2']).
%_lex(['old', 'over', 'years', 'second', 'per', 'year', 'two', 'same', 'next', 'state', 'won', 'new', 'more', 'million', 'students', 'season', 'each', 'during', 'one', 'school', 'later', 'three', 'team', 'following', 'first'], ['year/2']).
%_lex(['one', 'negate', 'battle', 'need', 'before', 'use', 'stanegate', 'two', 'tends', 'more', 'used', 'ability', 'power', 'effect', 'effects', 'such', 'fort', 'powers', 'well', 'roman', 'road', 'each', 'stonegate', 'advantage', 'south'], ['negate/2']).
%_lex(['family', 'within', 'one', 'county', 'born', 'village', 'district', 'min', '-', 'two', 'new', 'benjamin', 'gmina', 'vitamin', 'known', 'such', 'son', 'brahmin', 'amin', 'poland', 'later', 'american', 'franklin', 'time', 'first'], ['min/2']).
%_lex(['played', 'national', 'reunion', 'trade', 'player', 'church', 'united', 'union', 'workers', 'two', 'labor', 'communion', 'between', 'international', 'club', 'football', 'members', 'new', 'during', 'one', 'former', 'rugby', 'born', 'team', 'first'], ['union/3']).
%_lex(['money', 'over', 'number', 'one', 'total', 'species', 'gypsum', 'district', 'sum', 'two', 'mongolia', 'opossum', 'more', 'province', 'used', 'each', 'paid', 'possum', 'such', 'million', 'checksum', 'up', 'large', 'time', 'first'], ['sum/2']).
%_lex(['square', 'over', 'one', 'rate', 'approximately', 'year', 'vote', '80', 'total', 'votes', '20', 'area', 'percent', '40', 'according', 'more', 'received', 'water', 'kilometers', '90', 'population', '10', 'up', 'miles', '50'], ['percent/2']).
%_lex(['compare', 'regardless', 'help', 'less', 'being', 'over', 'number', 'one', 'homeless', 'orders', 'out', 'information', 'different', 'nonetheless', 'people', 'two', 'same', '1', 'much', 'between', 'performance', 'more', 'used', 'unless', 'time', 'lists', 'wireless', 'although', 'new', 'such', 'years', 'data', 'those', 'made', 'nevertheless', 'many', 'up', 'against', 'magnitude', 'each', 'following', 'page', 'first'], ['compareLess/3']).
%_lex(['square', 'people', 'squaremile', 'number', 'one', 'second', 'mile', 'km', 'again', 'error', 'area', 'west', 'sum', 'squared', 'two', 'per', '1', 'located', 'chi-squared', 'between', 'units', 'smile', 'east', 'more', 'function', 'used', 'north', 'route', 'each', 'long', 'game', 'half', 'using', 'population', 'emile', 'river', 'average', 'density', 'up', 'against', 'length', 'south', 'time', 'mean', 'housing', 'road', 'first'], ['squared_mile/2']).
%_lex(['square', 'less', 'one', 'mile', 'long', 'approximately', 'estimated', 'city', 'zone', 'density', 'away', 'people', 'per', '1', 'located', 'kilometer', 'north', 'greater', 'kilometers', 'line', 'population', 'average', 'area', 'river', 'road'], ['kilometer/2']).
%_lex(['compare', 'help', 'over', 'number', 'pacific', 'one', 'asian', 'makeup', 'racial', 'orders', 'native', 'even', 'information', 'different', 'furthermore', 'two', 'same', '1', 'much', 'between', 'performance', 'white', 'city', 'more', 'used', 'african', 'time', 'lists', 'races', 'new', 'such', 'years', 'data', 'those', 'many', 'against', 'american', 'magnitude', 'each', 'following', 'page', 'baltimore', 'first'], ['compareMore/3']).
%_lex(['square', 'people', 'number', 'one', 'second', 'mile', 'long', 'approximately', 'estimated', 'again', 'error', 'zone', 'area', 'sum', 'less', 'squared', 'two', 'per', '1', 'located', 'kilometer', 'chi-squared', 'between', 'more', 'function', 'used', 'north', 'greater', 'city', 'each', 'game', 'kilometers', 'using', 'line', 'population', 'river', 'average', 'density', 'up', 'against', 'length', 'time', 'mean', 'away', 'road', 'first'], ['squared_kilometer/2']).
%_lex(['en', 'fracturing', 'ten', 'increasingly', 'indeed', 'over', 'year', 'number', 'one', 'founded', 'services', 'second', 'during', 'cementing', 'best', 'out', 'high', 'based', 'script', 'corporation', 'top', 'two', 'douglas', 'desktop', 'stimulation', 'list', 'tail', 'station', 'new', 'team', 'greatest', 'schools', 'division', 'latin', 'frac', '10', 'season', 'atop', 'time', 'stop', '2006', 'ranked', 'western', 'dlig', 'world', '100', 'nation', '2007', 'state', 'league', 'school', 'language', 'communities', 'coat', 'university', 'well', 'up', 'teams', 'roberts', 'magazine', 'coiled', 'three', 'each', 'tubing', '2008', 'calfrac', 'first'], ['fracTopRanked/2']).
%_lex(['series', 'climax', 'one', 'lomax', 'reached', 'film', 'animax', 'movie', 'minimax', 'two', 'miramax', 'between', 'films', 'new', 'betamax', 'cinemax', 'used', 'song', 'max', 'story', 'game', 'during', 'television', 'up', 'first'], ['max/2']).
%_lex(['over', 'two', 'four', 'held', 'year', 'years', 'out', 'three', 'time', 'new', 'females', 'males', 'game', 'every', 'nearly', 'during', '100', 'one', 'day', 'school', 'world', '18', 'age', 'each', 'minutes', 'first'], ['every/3']).
%_lex(['diameter', 'square', 'cm', 'meter', 'one', 'high', 'meters', 'per', 'estimated', 'area', 'two', 'long', '1', 'kilometer', 'parameter', 'perimeter', 'used', 'around', 'inches', 'mm', 'm', 'up', 'large', 'each', 'small'], ['meter/2']).
%_lex(['en', 'fracturing', 'point', 'increasingly', 'indeed', 'one', 'founded', 'services', 'used', 'through', 'cementing', 'flavor', 'out', 'le', 'based', 'script', 'corporation', 'two', 'douglas', 'france', 'stimulation', 'taste', 'tail', 'quant', 'between', 'input', 'isoquant', 'more', 'latin', 'frac', 'de', 'equant', 'ptolemy', 'western', 'output', 'dlig', 'model', 'made', 'language', 'communities', 'coat', 'la', 'well', 'roberts', 'coiled', 'piquant', 'tubing', 'problem', 'calfrac', 'first'], ['fracQuant/3']).
%_lex(['number', 'son', '1st', 'two', 'book', 'take', 'taken', 'new', 'more', 'life', 'each', 'discount', 'recount', 'world', 'one', 'such', 'bank', 'viscount', 'count', 'account', 'later', 'according', 'published', 'time', 'first'], ['count/2']).
%_lex(['set', 'defined', 'm', 'argument', 'unary', 'computable', 'given', 'sum', 'note', 'geometric', 'more', 'formally', 'means', 'minimized', 'combinations', 'g', 'argmin', 'f', 'many', 'median', 'points', 'each'], ['argmin/4']).
%_lex(['love', 'people', 'commitment', 'one', 'through', 'human', 'church', 'court', 'christ', 'god', 'support', 'same', 'new', 'war', 'life', 'both', 'such', 'reaffirm', 'jesus', 'those', 'faith', 'world', 'affirm', 'position', 'order'], ['affirm/2']).
%_lex(['square', 'over', 'back', 'one', 'feet', 'set', 'right', 'out', 'mountain', 'built', 'two', 'long', 'located', 'new', 'first', 'barefoot', 'lightfoot', 'foot', 'high', 'm', 'up', 'each', 'tall', 'river', 'left'], ['foot/2']).
%_lex(['people', 'being', 'one', 'sea', 'different', 'temperature', 'area', '-', 'two', 'above', 'between', 'war', 'more', 'used', 'use', 'during', 'both', 'term', 'observatory', 'word', 'name', 'level', 'crimean', 'time', 'mean'], ['mean/2']).
%
%
%%END WACKYPEDIA PREDICATES
